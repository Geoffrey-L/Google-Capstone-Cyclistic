{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1247d524-c821-4799-b7a9-7963ac10b2a9",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Data Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e10429a-8af4-4036-9e5a-69251c1edc7c",
   "metadata": {},
   "source": [
    "# Standardization of station Ids"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "911cfbeb-88a3-40b6-8fb2-3d050f51b447",
   "metadata": {},
   "source": [
    "## Import and Concatenation of the files"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b58f37b5-b745-410b-be56-c2a874b357f6",
   "metadata": {},
   "source": [
    "**We start by importing the modules we need for data extraction and manipulation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a39dcf37-2621-40c2-86e4-a7cfb0fb9903",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import glob\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65168161-d541-4255-b511-eb1856a9d0d9",
   "metadata": {},
   "source": [
    "**We then define the files we will need to concatenate, and read them one by one using a for loop before grouping them together**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "69589cd3-f812-46d7-8e30-37501d0c8134",
   "metadata": {},
   "outputs": [],
   "source": [
    "files_path = r\"C:\\Users\\pocit\\OneDrive\\Documents\\formations_reconversion\\Google data analyst certificate\\Coursera8_Case_Study\\Bike_trip_files\\All_trips\\*.csv\"\n",
    "files = glob.glob(files_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b57541eb-421f-435b-b1f4-61d11ce5aea0",
   "metadata": {},
   "outputs": [],
   "source": [
    "files_list_cyclistic = []\n",
    "\n",
    "for f in files : # creating a loop to add files in sequence to our list\n",
    "    adding_files = pd.read_csv(f)\n",
    "    files_list_cyclistic.append(adding_files)\n",
    "    \n",
    "annual_cyclistic_trips = pd.concat(files_list_cyclistic, ignore_index =True) # we concatenate the files list resulting from our loop into a single dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f813511f-a78d-4e9e-9283-0199ca09475a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Total_bike_rides : 5552092\n"
     ]
    }
   ],
   "source": [
    "print(f\" Total_bike_rides : {len(annual_cyclistic_trips)}\") #we display the number of rows to make sure the 12 monthly files were correctly assembled"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d15ea229-b0ff-4f5f-8674-abce1b4667cc",
   "metadata": {},
   "source": [
    "## Mapping the correct Id for each station"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ddab4f4-09c0-4d5f-884c-05e860bed37e",
   "metadata": {},
   "source": [
    "**We keep the most recent station_name / station_Id pair for each station recorded in city trips for our reference period**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "9218dcc0-ea24-4203-8d75-a2e8380a6acf",
   "metadata": {},
   "outputs": [],
   "source": [
    "annual_cyclistic_trips['started_at'] = pd.to_datetime(annual_cyclistic_trips['started_at'])# we convert the started_at column to a date time format to make sure the data is sorted correctly\n",
    "\n",
    "starting_time_sorted = annual_cyclistic_trips.sort_values(by='started_at', ascending=False)# we sort the file by descending starting time\n",
    "\n",
    "reference_stations = starting_time_sorted[['start_station_name', 'start_station_id']].dropna() # we extract the relevant columns for the dictionnary\n",
    "\n",
    "reference_stations = reference_stations.drop_duplicates(subset=['start_station_name']) # we remove the duplicates from the station_name subset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e53900c-de00-4f16-ac03-1c043c7ed68b",
   "metadata": {},
   "source": [
    "**We then transform the data into a dictionnary**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "04e8500f-6a3c-4af9-abf8-90d6f2d028e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "station_mapping = reference_stations.set_index('start_station_name')['start_station_id'].to_dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc871a24-6159-40c4-b9c7-c58a07ab3533",
   "metadata": {},
   "source": [
    "## Standardizing the station Ids "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40344576-88fe-4b67-a4bf-fb2450aae66f",
   "metadata": {},
   "source": [
    "**Standardization of the starting stations**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "9143aa41-6916-4195-ba96-317dd8b78398",
   "metadata": {},
   "outputs": [],
   "source": [
    "annual_cyclistic_trips['new_starting_stations_id'] = annual_cyclistic_trips['start_station_name'].map(station_mapping) # we create a temporary column with the updated Ids for each station\n",
    "\n",
    "annual_cyclistic_trips['start_station_id'] = annual_cyclistic_trips['new_starting_stations_id'].fillna(annual_cyclistic_trips['start_station_id']) # we replace the values in the station_id column by the new ones without removing the old ids for the stations no longer in use "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed56c1f1-4c51-4067-bb85-42d3276ca3f8",
   "metadata": {},
   "source": [
    "**Standardization of the ending stations - we repeat the two steps above**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "c36b169c-0710-4470-8f84-fb29382fc4c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "annual_cyclistic_trips['new_ending_stations_id'] = annual_cyclistic_trips['end_station_name'].map(station_mapping)\n",
    "\n",
    "annual_cyclistic_trips['end_station_id'] = annual_cyclistic_trips['new_ending_stations_id'].fillna(annual_cyclistic_trips['end_station_id'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4f4fa5b-0045-4fb7-a796-45b2e2a279ab",
   "metadata": {},
   "source": [
    "**Removing the two columns we added previously**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "45a8bdef-6e92-4df3-85e0-7aa4a822230b",
   "metadata": {},
   "outputs": [],
   "source": [
    "annual_cyclistic_trips.drop(columns=['new_starting_stations_id', 'new_ending_stations_id'], inplace=True) # the two columns we created are not relevant for our future analysis and they make the file heavier, so we drop them"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12c06c4e-a0fe-488d-9d61-03f556c171fe",
   "metadata": {},
   "source": [
    "## Checking the result and exporting the file"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e11d5f5-23ef-4697-a9d6-67328de30128",
   "metadata": {},
   "source": [
    "**Checking the result**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "38a61baa-8889-4dc4-9437-55587ac6632d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              ride_id  rideable_type              started_at  \\\n",
      "8    3F0334B07B4D7F38  electric_bike 2025-02-04 07:57:26.522   \n",
      "9    1641FB083A2CDC74  electric_bike 2025-02-21 08:18:13.936   \n",
      "10   7F07E55F71DBB6E1  electric_bike 2025-02-10 17:58:19.301   \n",
      "38   FB3FF10F0CEC11E4   classic_bike 2025-02-25 10:40:09.706   \n",
      "108  AFA0BA782A200DF2  electric_bike 2025-02-10 16:15:36.555   \n",
      "\n",
      "                    ended_at         start_station_name start_station_id  \\\n",
      "8    2025-02-04 08:06:22.498  Ashland Ave & Division St         CHI00244   \n",
      "9    2025-02-21 08:27:47.866  Ashland Ave & Division St         CHI00244   \n",
      "10   2025-02-10 18:19:53.406  Ashland Ave & Division St         CHI00244   \n",
      "38   2025-02-25 10:53:33.887  Ashland Ave & Division St         CHI00244   \n",
      "108  2025-02-10 16:27:17.030  Ashland Ave & Division St         CHI00244   \n",
      "\n",
      "              end_station_name end_station_id  start_lat  start_lng  \\\n",
      "8            Clark St & Elm St       CHI00281  41.903394 -87.667867   \n",
      "9            Clark St & Elm St       CHI00281  41.903261 -87.668082   \n",
      "10         Wabash Ave & 9th St       CHI00448  41.903436 -87.668009   \n",
      "38           Clark St & Elm St       CHI00281  41.903450 -87.667747   \n",
      "108  Clinton St & Jackson Blvd       CHI01091  41.903450 -87.667747   \n",
      "\n",
      "       end_lat    end_lng member_casual Missing_trip_station  \\\n",
      "8    41.902973 -87.631280        member                  NaN   \n",
      "9    41.902973 -87.631280        member                  NaN   \n",
      "10   41.870769 -87.625734        member                  NaN   \n",
      "38   41.902973 -87.631280        member                  NaN   \n",
      "108  41.878317 -87.640981        member                  NaN   \n",
      "\n",
      "     ride_length_minutes  day_of_week day_name  \n",
      "8                    NaN          NaN      NaN  \n",
      "9                    NaN          NaN      NaN  \n",
      "10                   NaN          NaN      NaN  \n",
      "38                   NaN          NaN      NaN  \n",
      "108                  NaN          NaN      NaN  \n"
     ]
    }
   ],
   "source": [
    "print(annual_cyclistic_trips[annual_cyclistic_trips['start_station_name'] == 'Ashland Ave & Division St'].head()) # we check the result with a station that had an inconsistent Id in the oldest months of our dataset, and have now a standardised Id\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a2423c4-8944-48e4-8b20-910761d123fa",
   "metadata": {},
   "source": [
    "**exporting the file**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "9970f966-b4fb-4af1-a40c-267a47788a1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "annual_cyclistic_trips.to_csv('Cyclistic_Trips_Cleaned_202502_202601.csv', index=False) # we export the result as a new CSV file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "cf19bf70-c662-482f-957a-640f4de63a3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5552092, 13)\n"
     ]
    }
   ],
   "source": [
    "print(annual_cyclistic_trips.shape) # we make sure that the cleaned file contains the exact same number of rows as the total of the 12 monthly files we concatenated in the first part of the process"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d176258-74d3-4ab7-b10d-1b8920548e6c",
   "metadata": {},
   "source": [
    "# Further Processing of Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21bc02ef-8244-43f3-8ade-5c6f34d2423d",
   "metadata": {},
   "source": [
    "**Now that we have our Data in one concatenated file with up-to-date identifiers for each station, we can do a few more checks to ensure the data is clean and upright**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e7252ee-5908-484f-8b1b-e2718dcd6ce0",
   "metadata": {},
   "source": [
    "### First we make sure that every row in our dataset has a unique ride_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "472889f4-7151-4349-9fd6-0f1cb072d06f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5552092\n"
     ]
    }
   ],
   "source": [
    "unique_id = annual_cyclistic_trips['ride_id'].unique() # we check that the number of unique ride_id is the same as the total of rows in the file\n",
    "print(len(unique_id))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af621746-9574-4a58-a8f1-4dadb7a574ab",
   "metadata": {},
   "source": [
    "### Then we check that every ride happened in the time period of our study (the past 12 months)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "a30cd5f4-c0b1-4c6f-950d-8952b487e9b4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ride_id</th>\n",
       "      <th>rideable_type</th>\n",
       "      <th>started_at</th>\n",
       "      <th>ended_at</th>\n",
       "      <th>start_station_name</th>\n",
       "      <th>start_station_id</th>\n",
       "      <th>end_station_name</th>\n",
       "      <th>end_station_id</th>\n",
       "      <th>start_lat</th>\n",
       "      <th>start_lng</th>\n",
       "      <th>end_lat</th>\n",
       "      <th>end_lng</th>\n",
       "      <th>member_casual</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7323</th>\n",
       "      <td>9D2A64F3B1815359</td>\n",
       "      <td>electric_bike</td>\n",
       "      <td>2025-01-31 23:55:09.830</td>\n",
       "      <td>2025-02-01 00:00:10.352</td>\n",
       "      <td>Lincoln Ave &amp; Fullerton Ave</td>\n",
       "      <td>CHI00494</td>\n",
       "      <td>Clark St &amp; Wellington Ave</td>\n",
       "      <td>CHI00377</td>\n",
       "      <td>41.92</td>\n",
       "      <td>-87.65</td>\n",
       "      <td>41.94</td>\n",
       "      <td>-87.65</td>\n",
       "      <td>casual</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5517569</th>\n",
       "      <td>555372A890596494</td>\n",
       "      <td>electric_bike</td>\n",
       "      <td>2026-01-31 23:56:54.069</td>\n",
       "      <td>2026-01-31 23:59:33.214</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>41.92</td>\n",
       "      <td>-87.65</td>\n",
       "      <td>41.93</td>\n",
       "      <td>-87.65</td>\n",
       "      <td>member</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  ride_id  rideable_type              started_at  \\\n",
       "7323     9D2A64F3B1815359  electric_bike 2025-01-31 23:55:09.830   \n",
       "5517569  555372A890596494  electric_bike 2026-01-31 23:56:54.069   \n",
       "\n",
       "                        ended_at           start_station_name  \\\n",
       "7323     2025-02-01 00:00:10.352  Lincoln Ave & Fullerton Ave   \n",
       "5517569  2026-01-31 23:59:33.214                          NaN   \n",
       "\n",
       "        start_station_id           end_station_name end_station_id  start_lat  \\\n",
       "7323            CHI00494  Clark St & Wellington Ave       CHI00377      41.92   \n",
       "5517569              NaN                        NaN            NaN      41.92   \n",
       "\n",
       "         start_lng  end_lat  end_lng member_casual  \n",
       "7323        -87.65    41.94   -87.65        casual  \n",
       "5517569     -87.65    41.93   -87.65        member  "
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "first_and_last_entry = annual_cyclistic_trips.sort_values(by=['ended_at'], ascending=True)\n",
    "first_and_last_entry.iloc[[0, -1]] # we just check the first and last entry sorted by ending date and time, since the format has been harmonized for the entire column before"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b8c8a87-b3c9-4ee7-87d8-3a72bf7549d4",
   "metadata": {},
   "source": [
    "### We can check the cross-field concordance of the starting and ending dates to be sure it stays coherent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "fc7c6269-4ecc-4360-bbd7-20bc19d94dd4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29\n",
      "                  ride_id  rideable_type              started_at  \\\n",
      "4942264  5D010AFEA6850513  electric_bike 2025-11-02 01:52:37.475   \n",
      "4943812  D1E5316AD88ECD45   classic_bike 2025-11-02 01:50:39.702   \n",
      "4945806  3AF2F8908C9386F8   classic_bike 2025-11-02 01:57:57.512   \n",
      "4960702  19386939ECD81B33  electric_bike 2025-11-02 01:55:34.399   \n",
      "4969070  083534D28DA37F72   classic_bike 2025-11-02 01:17:57.001   \n",
      "\n",
      "                        ended_at               start_station_name  \\\n",
      "4942264  2025-11-02 01:13:24.728  Pine Grove Ave & Wellington Ave   \n",
      "4943812  2025-11-02 01:14:04.164        Clark St & Ida B Wells Dr   \n",
      "4945806  2025-11-02 01:33:52.225           State St & Chicago Ave   \n",
      "4960702  2025-11-02 01:21:31.873           Broadway & Sheridan Rd   \n",
      "4969070  2025-11-02 01:05:27.752              Clark St & Grace St   \n",
      "\n",
      "        start_station_id              end_station_name end_station_id  \\\n",
      "4942264         CHI02158       Wilton Ave & Addison St       CHI02055   \n",
      "4943812         CHI00216      Paulina St & Division St       CHI00244   \n",
      "4945806         CHI01772  Ravenswood Ave & Berteau Ave       CHI00471   \n",
      "4960702         CHI00476                           NaN            NaN   \n",
      "4969070         CHI00301        Grace St & Central Ave       CHI01799   \n",
      "\n",
      "         start_lat  start_lng    end_lat    end_lng member_casual  \\\n",
      "4942264  41.936510 -87.641190  41.947459 -87.653216        member   \n",
      "4943812  41.875933 -87.630585  41.903553 -87.670429        casual   \n",
      "4945806  41.896617 -87.628579  41.957921 -87.673567        member   \n",
      "4960702  41.952833 -87.649993  41.960000 -87.740000        member   \n",
      "4969070  41.950780 -87.659172  41.949533 -87.767265        member   \n",
      "\n",
      "        Missing_trip_station  ride_length_minutes  day_of_week day_name  \n",
      "4942264                  NaN                  NaN          NaN      NaN  \n",
      "4943812                  NaN                  NaN          NaN      NaN  \n",
      "4945806                  NaN                  NaN          NaN      NaN  \n",
      "4960702                  NaN                  NaN          NaN      NaN  \n",
      "4969070                  NaN                  NaN          NaN      NaN  \n"
     ]
    }
   ],
   "source": [
    "date_error = annual_cyclistic_trips[annual_cyclistic_trips['ended_at'] < annual_cyclistic_trips['started_at']]\n",
    "print(len(date_error))\n",
    "print(date_error.head(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba16478b-b622-47d0-968d-8aababf901d0",
   "metadata": {},
   "source": [
    "We notice a few outliers, happening on the same night of november 2nd. We can infer from this simultaneity of outliers that the events must coincide with the switch to Winter time in Chicago. But for the sake of accuracy, we decide to remove these outliers from the analysis, since their share in the total of trips is negligible"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0a5eacac-5054-48f4-8253-d6e100fa3b8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "annual_cyclistic_trips.drop(date_error.index, inplace=True) # we drop the outliers from the table"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5213e548-ae65-400f-88bf-e6f396c91419",
   "metadata": {},
   "source": [
    "### It's possible to verify for outliers or null values in the the ride_id column to make sure the data stays coherent in this section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "4b8fe6db-3162-4468-a002-2dc914217a1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "ride_id_error = annual_cyclistic_trips[annual_cyclistic_trips['ride_id'].str.len() != 16] # all Ids are strings of 16 characters\n",
    "print(len(ride_id_error))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7367437f-5cb6-4577-a851-2cf1879629c0",
   "metadata": {},
   "source": [
    "### When sorting the monthly files in the prepare phase, we noticed during our presence check that some fields in the start_station_name, start_station_id, end_station_name and end_station_id columns were empty."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe81dc4f-4308-4e51-80ef-b7010208775f",
   "metadata": {},
   "source": [
    "when a station_name field is empty, the corresponding station_id on the row is also empty. The number of occurrences suggest that some users could take bikes outside of and not returning it to a designated station. Since these empty data can provide insights into our analysis, we make the choice to fill them out with a specific mention, so we have the option to analyze it further later. Nevertheless, the integration of empty data means the results of our measurements as conducted in the analyze phase must be taken with these limitations in mind."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "9131b459-c8ee-43a9-8f6d-b9d34a93f229",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1862950\n"
     ]
    }
   ],
   "source": [
    "empty_station = (annual_cyclistic_trips['start_station_name'].isna()) | (annual_cyclistic_trips['end_station_name'].isna()) # we create a Boolean to outline the missing start and end stations \n",
    "print(sum(empty_station))\n",
    "annual_cyclistic_trips['Missing_trip_station'] = 'Stations Complete' # we create a new column to differenciate the 'complete bike trip' rows with both station names, from the 'incomplete trip with missing station' rows\n",
    "annual_cyclistic_trips.loc[empty_station, 'Missing_trip_station'] = 'Incomplete stations' # we fill the incomplete rows with the 'Incomplete stations' mention\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d0c21d7-c7ac-4b3e-afba-5885f360f88d",
   "metadata": {},
   "source": [
    "# Adding more columns to prepare for the analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4926fd09-2a9f-4466-9817-ae65b0eef761",
   "metadata": {},
   "source": [
    "**Lastly we can add a few more columns to our table to help us deliver the expected insights and anwsers to our manager**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59379abd-44b1-41e2-b606-9e99b93eff32",
   "metadata": {},
   "source": [
    "## Measuring ride lengths"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0968d2e1-7c09-4f06-a147-ea92ada99fb0",
   "metadata": {},
   "source": [
    "### Creating a column to calculate the length of each ride"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "138a52cc-8fcc-4f5c-927c-c45fc91a019f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               started_at                ended_at  ride_length_minutes\n",
      "0 2025-02-25 21:21:21.171 2025-02-25 21:30:09.941                 8.81\n",
      "1 2025-02-08 14:55:13.493 2025-02-08 15:13:39.890                18.44\n",
      "2 2025-02-24 00:32:56.553 2025-02-24 00:38:21.711                 5.42\n",
      "3 2025-02-07 17:00:38.646 2025-02-07 17:34:29.012                33.84\n",
      "4 2025-02-10 14:56:56.565 2025-02-10 15:01:18.745                 4.37\n",
      "count    5.552063e+06\n",
      "mean     1.609683e+01\n",
      "std      5.579980e+01\n",
      "min      0.000000e+00\n",
      "25%      5.400000e+00\n",
      "50%      9.440000e+00\n",
      "75%      1.658000e+01\n",
      "max      1.574900e+03\n",
      "Name: ride_length_minutes, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "annual_cyclistic_trips['started_at'] = pd.to_datetime(annual_cyclistic_trips['started_at']) # first we verify that the date-time columns have the correct format\n",
    "annual_cyclistic_trips['ended_at'] = pd.to_datetime(annual_cyclistic_trips['ended_at'])\n",
    "\n",
    "annual_cyclistic_trips['ride_length'] = annual_cyclistic_trips['ended_at'] - annual_cyclistic_trips['started_at'] # We then calculate the difference between the two points\n",
    "annual_cyclistic_trips['ride_length_minutes'] = (annual_cyclistic_trips['ride_length'].dt.total_seconds() / 60).round(2) # We choose to convert the ride_length to minutes only, since it will allow a clearer display of the statistics for analysis.We round the result to two decimals only for a better clarity of display\n",
    "\n",
    "print(annual_cyclistic_trips[['started_at', 'ended_at','ride_length_minutes']].head()) # we verify the function with the five first rows \n",
    "print(annual_cyclistic_trips['ride_length_minutes'].describe()) # we show key statistics for a better understanding of the dataset, and round the measures to two decimals for better clarity\n",
    "\n",
    "annual_cyclistic_trips.drop(columns=['ride_length'], inplace=True) # we delete the first ride_length column since it's not as usable as the second one"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f2f54f5-e009-4f1a-afe4-96c008993789",
   "metadata": {},
   "source": [
    "The minimal and maximal lengths returned are surprising : The shortest trip lasted only a fraction of a second, whereas the longest one lasted more than 24 hours (1574 minutes). Since these durations don't look coherent with a standard use of a rented bike in a city, we decide to implement a method to detect outliers, that will help us remove the inconsistent data from our final table."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "274de205-2c3d-44bd-9a9f-f2d79a91ae8f",
   "metadata": {},
   "source": [
    "### Choosing an outlier detection method"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "103aaf9d-e8d2-4a8a-9a81-44deeb1cb6a1",
   "metadata": {},
   "source": [
    "We can start by trying to isolate the data outliers based on the distance from the standard deviation, following the two-sigma rule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5aa5d564-3687-4de9-9838-35bbc8c546dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean duration : 16.10 min\n",
      "Standard Deviation : 55.80 min\n",
      "Lower limit : -95.50277405532776\n",
      "Upper limit : 127.69644088151472\n"
     ]
    }
   ],
   "source": [
    "mean_duration = annual_cyclistic_trips['ride_length_minutes'].mean() # we start by calculating the mean and the standard deviation separately\n",
    "std_duration = annual_cyclistic_trips['ride_length_minutes'].std()\n",
    "\n",
    "print(f\"Mean duration : {mean_duration:.2f} min\")\n",
    "print(f\"Standard Deviation : {std_duration:.2f} min\")\n",
    "\n",
    "standard_deviation_lower_limit = mean_duration - (2* std_duration) # we are considering for this calculation that the data we are using is a normal distribution, and that we need to capture at least 95% of it, following the two-sigma rule\n",
    "standard_deviation_upper_limit = mean_duration + (2* std_duration)\n",
    "\n",
    "print( f\"Lower limit : {standard_deviation_lower_limit}\")\n",
    "print( f\"Upper limit : {standard_deviation_upper_limit}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4daedcc-b78c-422d-82aa-0fcc6e42b38b",
   "metadata": {},
   "source": [
    "We deduce from this findings that the standard deviation may not be the best indicator to help us remove outliers, since a negative lower limit isn't relevant in the data we are observing, and an upper limit of only 127.7 minutes seems overly exclusive, since a lot of users are renting bike for a whole day. We decide to apply some common logic, based on the business operations of Cyclistic to define outliers as follows :\n",
    "\n",
    "- A bike trip shorter than one minute probably doesn't relate to a normal use of the product, but rather to a technical issue or a bug ;\n",
    "- A bike trip of more than 24 consecutive hours for a city rented bike company is unusually long, and can indicate a technical issue, or a theft\n",
    "\n",
    "Based on business logic and estimations, we will measure the number of bike trips shorter than 1 minute and longer than 24 hours"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41be8861-fae6-4590-a98d-e12cd9bd87e0",
   "metadata": {},
   "source": [
    "### Filtering and dealing with outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "712036f8-8603-4a36-a237-c8e23fb532d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of trips that are too short : 148372\n",
      "Number of trips that are too long : 5707\n"
     ]
    }
   ],
   "source": [
    "too_short_trips = annual_cyclistic_trips[annual_cyclistic_trips['ride_length_minutes'] < 1] # we start by filtering trips that are too short to be relevant\n",
    "too_long_trips = annual_cyclistic_trips[annual_cyclistic_trips['ride_length_minutes'] > 1440] # we do the same for the trips of more than 24 hours\n",
    "\n",
    "print(f\"Number of trips that are too short : {len(too_short_trips)}\") # we print the results\n",
    "print(f\"Number of trips that are too long : {len(too_long_trips)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9d01a91-0c3a-4df8-8643-770a0e5d1e36",
   "metadata": {},
   "source": [
    "Let's see how these numbers translate in percentage of the total rides observed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "53f02347-790c-46de-9a3f-556cbfeeb49d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage of inconsistent trips : 2.7751666362575493 %\n"
     ]
    }
   ],
   "source": [
    "inconsistent_trips = len(too_short_trips) + len(too_long_trips) # number of inconsistent trips\n",
    "share_of_inconsistent_trips = (inconsistent_trips/len(annual_cyclistic_trips))*100 # share of inconsistent trips in the total number of trips\n",
    "\n",
    "print(f\"Percentage of inconsistent trips : {share_of_inconsistent_trips} %\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "367599e2-6c7d-415e-a44d-70f628add04e",
   "metadata": {},
   "source": [
    "Since the total percentage of the outliers as defined in the previous step is less than 5%, and that we don't consider these rides as valid, we take the decisions to delete them from the table before beginning our analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "979b326e-fc9c-4b7d-bc6f-1b67b6bda544",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count   5397984.00\n",
       "mean         14.96\n",
       "std          29.47\n",
       "min           1.00\n",
       "25%           5.68\n",
       "50%           9.69\n",
       "75%          16.85\n",
       "max        1439.98\n",
       "Name: ride_length_minutes, dtype: float64"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "annual_cyclistic_trips = annual_cyclistic_trips[\n",
    "    (annual_cyclistic_trips['ride_length_minutes'] >= 1) &\n",
    "    (annual_cyclistic_trips['ride_length_minutes'] <= 1440)\n",
    "    ] # we choose to keep only th rides that lasted bewteen 1 minute and 1440 minutes\n",
    "\n",
    "annual_cyclistic_trips.shape # we check that the total count is correctly updated after the deletion\n",
    "annual_cyclistic_trips['ride_length_minutes'].describe().round(2) # we double check with the new min and max length of rides"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "078f7239-eb9e-41f7-be98-4adba41a7931",
   "metadata": {},
   "source": [
    "## Indicating the day of the week for the trips"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "253daaf8-dc97-494a-a355-09b13c7b7ac3",
   "metadata": {},
   "source": [
    "**Knowing the day of the week when each trip started could give us further insights for comparing casual users with members in our analysis**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c86f772c-e00b-4fa5-a51b-5181efe56018",
   "metadata": {},
   "source": [
    "### Creation of a day_of_week column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "9e29a61e-a194-4812-91eb-0819240fc6c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               started_at  day_of_week\n",
      "0 2025-02-25 21:21:21.171            1\n",
      "1 2025-02-08 14:55:13.493            5\n",
      "2 2025-02-24 00:32:56.553            0\n",
      "3 2025-02-07 17:00:38.646            4\n",
      "4 2025-02-10 14:56:56.565            0\n"
     ]
    }
   ],
   "source": [
    "annual_cyclistic_trips['day_of_week'] = annual_cyclistic_trips['started_at'].dt.dayofweek # we return the number of the week day corresponding to the starting date_time of the trip \n",
    "\n",
    "print(annual_cyclistic_trips[['started_at', 'day_of_week']].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bf79298-9b2f-4514-a14d-919242e74f88",
   "metadata": {},
   "source": [
    "We now know which day of the week each trip started, considering Monday = 0 and Sunday = 6. For a better grasp of this data, we add a last column, corresponding to the name of the corresponding day of week in full letters :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "eb742768-1c23-40d7-963e-c37d19b6bf5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               started_at  day_of_week  day_name\n",
      "0 2025-02-25 21:21:21.171            1   Tuesday\n",
      "1 2025-02-08 14:55:13.493            5  Saturday\n",
      "2 2025-02-24 00:32:56.553            0    Monday\n",
      "3 2025-02-07 17:00:38.646            4    Friday\n",
      "4 2025-02-10 14:56:56.565            0    Monday\n"
     ]
    }
   ],
   "source": [
    "annual_cyclistic_trips['day_name'] = annual_cyclistic_trips['started_at'].dt.day_name()\n",
    "print(annual_cyclistic_trips[['started_at', 'day_of_week', 'day_name']].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf8b69b0-3943-48c5-80f0-886fa930c3fd",
   "metadata": {},
   "source": [
    "This column adds a layer of accessibility to our table, and will help explore some more insights regarding the use of cyclistic's bikes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "243b9d54-ed62-4f6a-b503-403069e3a06d",
   "metadata": {},
   "source": [
    "Finally, we can export our cleaned and updated table to a csv file, before beginning the Anaylisis phase."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "d8d8174d-1b88-4b88-bf48-5da46cb24ede",
   "metadata": {},
   "outputs": [],
   "source": [
    "annual_cyclistic_trips.to_csv('Cyclistic_Trips_Final_202502_202601.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2406bf42-8b1b-4356-9d0f-5befbf9d3c4f",
   "metadata": {},
   "source": [
    "**We prepared the data and took appropriate cleaning measures for further analysis. This will give us a reliable and credible working base to answer our main question, which was : how exactly does the usage of bikes differ between casual users and members ?**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
